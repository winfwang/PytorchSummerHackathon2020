{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596953323953",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">https://www.youtube.com/watch?v=9aYuQmMJvjA\n",
    "\n",
    "# Convnet Intro - Convolutional Neural Networks (p. 5)\n",
    "\n",
    "- <mark>Convolutional Neural Networks (CNN)</mark> mainly used for image tasks; but it's out-performing ***recurrent neural networks*** so it's good in training **sequential** types of data\n",
    "- In image tasks, it tasks in images in it's raw form - even 3D images. **NO** need to flatten or adjust.\n",
    "- <mark>Convolutions</mark>: goal is to locate features of a image through its pixels\n",
    "- Image as input is **called** a <mark>window</mark> or <mark>\"X by Y\" (dimension) \"Convolution Kernel\"</mark>\n",
    "- Convolution first finds edges, curves, then searches a more complex one level up like a shape (multiple edges or curves) and so on...\n",
    "\n",
    "![alt text](img/ConvolutionConcept.png)\n",
    "\n",
    "- after convolution, then <mark>pooling</mark>\n",
    "- <mark>Max Pooling</mark>: algorithm that takes maximum value generated by the convolution process in every window generated, **basically simplifying the image more and more**\n",
    "- Every level up (layer) of convolution **INCREASES** kernel/window dimension\n",
    "- underestimated step not in tutorials is the **Preprocessing** step of datasets. this is to prepare it for the neural network and realistically it'll always take a long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REBUILD_DATA = True\n",
    "\n",
    "class DogsVSCats():\n",
    "    # we're going to make images 50 x 50\n",
    "    IMG_SIZE = 50\n",
    "    CATS = \"PetImages/Cat\"\n",
    "    DOGS = \"PetImages/Dog\"\n",
    "    LABELS = {CATS: 0, DOGS: 1}\n",
    "    training_data = []\n",
    "    catcount = 0\n",
    "    dogcount = 0\n",
    "\n",
    "    def make_training_data(self):\n",
    "        for label in self.LABELS:\n",
    "            print(label)\n",
    "            for f in tqdm(os.listdir(label)):\n",
    "                path = os.path.join(label)\n",
    "                img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n"
   ]
  }
 ]
}