{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597806078779",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">https://www.youtube.com/watch?v=9aYuQmMJvjA\n",
    "\n",
    "# Convnet Intro - Convolutional Neural Networks (p. 5)\n",
    "\n",
    "- <mark>Convolutional Neural Networks (CNN)</mark> mainly used for image tasks; but it's out-performing ***recurrent neural networks*** so it's good in training **sequential** types of data\n",
    "- In image tasks, it tasks in images in it's raw form - even 3D images. **NO** need to flatten or adjust.\n",
    "- <mark>Convolutions</mark>: goal is to locate features of a image through its pixels\n",
    "- Image as input is **called** a <mark>window</mark> or <mark>\"X by Y\" (dimension) \"Convolution Kernel\"</mark>\n",
    "- Convolution first finds edges, curves, then searches a more complex one level up like a shape (multiple edges or curves) and so on...\n",
    "\n",
    "![alt text](img/ConvolutionConcept.png)\n",
    "\n",
    "- after convolution, then <mark>pooling</mark>\n",
    "- <mark>Max Pooling</mark>: algorithm that takes maximum value generated by the convolution process in every window generated, **basically simplifying the image more and more**\n",
    "- Every level up (layer) of convolution **INCREASES** kernel/window dimension\n",
    "- underestimated step not in tutorials is the **Preprocessing** step of datasets. this is to prepare it for the neural network and realistically it'll always take a long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cats v Dogs Dataset found here:** https://www.microsoft.com/en-us/download/confirmation.aspx?id=54765"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "REBUILD_DATA = False\n",
    "\n",
    "class DogsVSCats():\n",
    "    # we're going to make images 50 x 50\n",
    "    IMG_SIZE = 50\n",
    "    CATS = \"PetImages/Cat\"\n",
    "    DOGS = \"PetImages/Dog\"\n",
    "    LABELS = {CATS: 0, DOGS: 1}\n",
    "    training_data = []\n",
    "    catcount = 0\n",
    "    dogcount = 0\n",
    "\n",
    "    def make_training_data(self):\n",
    "        for label in self.LABELS:\n",
    "            print(label)\n",
    "            for f in tqdm(os.listdir(label)):\n",
    "                try:\n",
    "                    path = os.path.join(label, f)\n",
    "                    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "                    img = cv2.resize(img, (self.IMG_SIZE, self.IMG_SIZE))\n",
    "                    self.training_data.append([np.array(img), np.eye(2)[self.LABELS[label]]])\n",
    "\n",
    "                    if label == self.CATS:\n",
    "                        self.catcount += 1\n",
    "                    elif label == self.DOGS:\n",
    "                        self.dogcount += 1\n",
    "                # handle empty images\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "                    #print(str(e))\n",
    "        np.random.shuffle(self.training_data)\n",
    "        np.save(\"training_data.npy\", self.training_data)\n",
    "        print(\"\\nCats: \", self.catcount)\n",
    "        print(\"\\nDogs: \", self.dogcount)\n",
    "\n",
    "if REBUILD_DATA:\n",
    "    dogsvcats = DogsVSCats()\n",
    "    dogsvcats.make_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "np.eye(10)[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.load(\"training_data.npy\", allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "24946\n"
    }
   ],
   "source": [
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}